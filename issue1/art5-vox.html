<!DOCTYPE>
<html>
	<!-- Style Is an Algorithm
No one is original anymore, not even you.

By Kyle Chayka  Apr 17, 2018, 10:00am EDT
Illustrations by Momo Pixel -->

<!-- The message of many things in America is “Like this or die.”
— George W.S. Trow, Within the Context of No Context, 1980 -->

The Seeing Robot
The camera is a small, white, curvilinear monolith on a pedestal. Inside its smooth casing are a microphone, a speaker, and an eye-like lens. After I set it up on a shelf, it tells me to look straight at it and to be sure to smile! The light blinks and then the camera flashes. A head-to-toe picture appears on my phone of a view I’m only used to seeing in large mirrors: me, standing awkwardly in my apartment, wearing a very average weekday outfit. The background is blurred like evidence from a crime scene. It is not a flattering image.

Amazon’s Echo Look, currently available by invitation only but also on eBay, allows you to take hands-free selfies and evaluate your fashion choices. “Now Alexa helps you look your best,” the product description promises. Stand in front of the camera, take photos of two different outfits with the Echo Look, and then select the best ones on your phone’s Echo Look app. Within about a minute, Alexa will tell you which set of clothes looks better, processed by style-analyzing algorithms and some assistance from humans. So I try to find my most stylish outfit, swapping out shirts and pants and then posing stiffly for the camera. I shout, “Alexa, judge me!” but apparently that’s unnecessary.

What I discover from the Style Check™ function is as follows: All-black is better than all-gray. Rolled-up sleeves are better than buttoned at the wrist. Blue jeans are best. Popping your collar is actually good. Each outfit in the comparison receives a percentage out of 100: black clothes score 73 percent against gray clothes at 27 percent, for example. But the explanations given for the scores are indecipherable. “The way you styled those pieces looks better,” the app tells me. “Sizing is better.” How did I style them? Should they be bigger or smaller?

The Echo Look won’t tell you why it’s making its decisions. And yet it purports to show us our ideal style, just as algorithms like Netflix recommendations, Spotify Discover, and Facebook and YouTube feeds promise us an ideal version of cultural consumption tailored to our personal desires. In fact, this promise is inherent in the technology itself: Algorithms, as I’ll loosely define them, are sets of equations that work through machine learning to customize the delivery of content to individuals, prioritizing what they think we want, and evolving over time based on what we engage with.

Confronting the Echo Look’s opaque statements on my fashion sense, I realize that all of these algorithmic experiences are matters of taste: the question of what we like and why we like it, and what it means that taste is increasingly dictated by black-box robots like the camera on my shelf.

Theories of Taste
In his 2017 book Taste, the Italian philosopher Giorgio Agamben digs up the roots of the word. Historically, it is defined as a form of knowledge through pleasure, from perceiving the flavor of food to judging the quality of an object. Taste is an essentially human capacity, to the point that it is almost subconscious: We know whether we like something or not before we understand why. “Taste enjoys beauty, without being able to explain it,” Agamben writes. He quotes Montesquieu: “This effect is principally founded on surprise.” Algorithms are meant to provide surprise, showing us what we didn’t realize we’d always wanted, and yet we are never quite surprised because we know to expect it.

Philosophers in the 18th century defined taste as a moral capacity, an ability to recognize truth and beauty. “Natural taste is not a theoretical knowledge; it’s a quick and exquisite application of rules which we do not even know,” wrote Montesquieu in 1759. This unknowingness is important. We don’t calculate or measure if something is tasteful to us; we simply feel it. Displacing the judgment of taste partly to algorithms, as in the Amazon Echo Look, robs us of some of that humanity.

Every cultural object we aestheticize and consume — “the most everyday choices of everyday life, e.g., in cooking, clothing or decoration,” Pierre Bourdieu writes in his 1984 book Distinction: A Social Critique of the Judgement of Taste — is a significant part of our identities and reflects who we are. “Taste classifies, and it classifies the classifier,” Bourdieu adds. If our taste is dictated by data-fed algorithms controlled by massive tech corporations, then we must be content to classify ourselves as slavish followers of robots.

But Fashion Is Already Arbitrary
We might say that “taste” is the abstract, moralized knowledge, while “style” is its visual expression. Fashion makes taste easily visible as style, in part because its distinctions between color or cut in clothing are so specific and yet so random (“rules which we don’t even know”). In the past, a whimsical consensus among elites dictated fashion culture; a royal court or an echelon of magazine editors imposed a certain taste from the top of society, down.

<!-- TASTE IS AN ESSENTIALLY HUMAN CAPACITY, TO THE POINT THAT IT IS ALMOST SUBCONSCIOUS: WE KNOW WHETHER WE LIKE SOMETHING OR NOT BEFORE WE UNDERSTAND WHY. -->

Roland Barthes noticed this arbitrariness in his 1960 essay Blue Is in Fashion This Year. Barthes scrutinizes a fragment of text from a fashion magazine — “blue is in fashion this year” — to see where its thesis, that a particular color is particularly tasteful right now, comes from. His conclusion is that it doesn’t come from anywhere: “We are not talking about a rigorous production of meaning: the link is neither obligatory nor sufficiently motivated.” Blue is not in fashion because it is particularly functional, nor is it symbolically linked to some wider economic or political reality; the statement has no semantic logic. Style, Barthes argues, is an inexplicable equation (a faulty algorithm).

That Scene from The Devil Wears Prada
Further evidence of the artificial and hierarchical nature of style in the past can be found in that scene from the 2006 film The Devil Wears Prada, in which Meryl Streep (as magazine editor and Anna Wintour facsimile Miranda Priestly) tells her assistant played by Anne Hathaway that the chunky blue sweater she is wearing was, in essence, chosen for her. “That blue represents millions of dollars and countless jobs, and it’s sort of comical how you think you made a choice that exempts you from the fashion industry when, in fact, you’re wearing a sweater that was selected for you by the people in this room from a pile of stuff,” Streep says.

In other words, blue is in fashion this year because some people decided it was. You, the non-tastemaker, have no choice in the matter.

Data-Based Fashion
Is it possible that instead of this artificial fashion language, algorithms like those powering Alexa could create a more systemic, logical construction of fashion aesthetics built on data? Blue is in fashion this year because 83.7 percent of users purchased (or clicked like on) blue shirts, the Amazon Echo Look algorithm says, therefore it is in fashion, therefore businesses should manufacture more blue shirts, and you, the customer, will buy and wear them. No human editors needed.

I’m not sure if this technology-derived algorithmic facticity of taste is better or worse than Meryl Streep-Anna Wintour deciding what I wear, which might be the core concern of this essay.

“Collapsing Dominant”
When modes of tastes change, there is a certain fear: Am I in or out? Do I understand the new or am I stuck in the old? In 1980, the New Yorker published George W.S. Trow’s essay describing this feeling under the title of “Within the Context of No Context,” from which I took the epigraph and structure for this piece. Trow’s essay came out as a book in 1981 and again in 1997. In the appended introduction to the 1997 edition, he uses the phrase “collapsing dominant” to describe a situation in which an older, established mode of cultural authority, or a taste regime, is fading and being replaced by a newer one. These regimes have two parts: the subjects of taste and the way taste is communicated.

Today we are seeing the collapse of the dominant regime that Trow originally observed emerging, mass-media television, which had previously replaced the moralistic mid-century novels of New England WASPs. Now, we have Instagram likes, Twitter hashtags, and Google-distributed display advertising spreading taste values. Instead of the maximalist, celebrity-driven, intoxicant culture of ‘70s television — Nixon, Star Wars, shag rugs, cocaine, nuclear bombs — we now have the flattened, participatory, somehow salutary aesthetic of avocado toast, Outdoor Voices leggings, reclaimed wood, Sky Ting yoga classes, and succulents in ceramic planters.

That we are in the midst of this shift in taste might help explain our larger mood of instability and paranoia (or is it just me?). We can’t figure out what might be sustainable to identify with, to orient our taste on. The algorithm suggests that we trust it, but we don’t entirely want to. We crave a more “authentic,” lasting form of meaning.

The Death of Svpply
In 2009, a designer named Ben Pieratt, now living in Massachusetts, launched Svpply. It was a kind of online social network based on shopping, where invitation-only members could curate selections of products from elsewhere on the internet and users could follow their favorite tastemakers. Eventually, any user could become a curator. I remember it from the time as a calm, limpid pool in the midst of so much internet noise. The site presented only cool clothes, bags, and accessories, all chosen by individual humans, since algorithmic feeds weren’t widely deployed at the time. On Svpply you could find the melange of signifiers of a certain class of early-adopter design-bro: minimalist sneakers, fancy T-shirts, Leica cameras, and drop-crotch sweatpants.

<!-- THE ALGORITHM SUGGESTS THAT WE TRUST IT, BUT WE DON’T ENTIRELY WANT TO. -->

In 2012, eBay acquired the company and quickly shut it down. In 2014, Pieratt launched a Kickstarter for Very Goods, a Svpply replacement that’s still active. Today he sees Svpply as a cautionary tale about the limits of human curation on the internet. Over the phone, we talk about how taste doesn’t really scale. The bigger a platform gets, the harder it is to maintain a particular sense of style. By opening the platform, Pieratt had tried to “convert from a human-driven community into a machine,” he explains. “When we lost the exclusivity, people didn’t really care anymore.” Svpply’s innate sense of uniqueness didn’t survive: “If everyone’s editing Vogue, it wouldn’t be Vogue.”

Another question: How good of a tastemaker can a machine ultimately be?

Human- v. Machine-Curation
I worry that we are moving from a time of human curation (early Svpply) to a time in which algorithms drive an increasingly large portion of what we consume (the Facebook feed). This impacts not only the artifacts we experience but also how we experience them. Think of the difference between a friend recommending a clothing brand and something showing up in targeted banner ads, chasing you around the internet. It’s more likely that your friend understands what you want and need, and you’re more likely to trust the recommendation, even if it seems challenging to you.

Maybe it’s a particularly shapeless garment or a noisy punk track. If you know the source of the suggestion, then you might give it a chance and see if it meshes with your tastes. In contrast, we know the machine doesn’t care about us, nor does it have a cultivated taste of its own; it only wants us to engage with something it calculates we might like. This is boring. “I wonder if, at the core of fashion, the reason we find it fascinating is that we know there’s a human at the end of it,” Pieratt says. “We’re learning about people. If you remove that layer of humanity from underneath, does the soul of the interest leave with it?”

Pieratt makes a further distinction between style and taste. Style is a superficial aesthetic code that is relatively simple to replicate, whereas taste is a kind of wider aesthetic intelligence, able to connect and integrate disparate experiences. Algorithms can approximate the former — telling me I should wear a blue shirt — but can’t approximate the latter because the machine can’t tell me why it thinks I should wear a blue shirt or what the blue shirt might mean to me. When a machine has taken over the exploration of taste, the possibility of suddenly feeling something from a surprising object is narrowed to only what the machine decides to expose. “I don’t think there’s such a thing as machine taste yet,” says Pieratt.

Of course, he and I might just be part of the fading regime, our “collapsing dominant.” The dystopian babies of 2018 raised on algorithmic Spiderman-slash-Frozen YouTube videos may have different appetites in the future.

Taste Optimization
The threat of banality (or the lack of surprise) implicit in full machine curation reminds me of the seemingly random vocabulary meant to improve SEO on Craigslist posts. As one chair listing I encountered put it: “Goes with herman miller eames vintage mid century modern knoll Saarinen dwr design within reach danish denmark abc carpet and home arm chair desk dining slipper bedroom living room office.”

Imagine the optimized average of all of these ideas. The linguistic melange forms a taste vernacular built not on an individual brand identity or a human curator but a freeform mass of associations meant to draw the viewer in by any means necessary. If you like this, you’ll probably like that. Or, as a T-shirt I bought in Cambodia a decade ago reads, “Same same but different.” The slogan pops into my mind constantly as I scroll past so many content modules, each unique and yet unoriginal.




</html>